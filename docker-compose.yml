services:
  # -----------------------------
  # 1. The Neo4j Graph Database
  # -----------------------------
  neo4j-db:
    image: neo4j:5.26.0-enterprise  # Using Enterprise (free for dev) or 'neo4j:5.26.0' for community
    container_name: llm_knowledge_graph_db
    ports:
      - "7474:7474" # HTTP (Browser UI)
      - "7687:7687" # Bolt (Application connection)
    environment:
      # Authentication
      - NEO4J_AUTH=neo4j/password123
      # Essential Plugins for GraphRAG & Vector Search
      - NEO4J_PLUGINS=["apoc", "graph-data-science"]
      # License agreement required for GDS/Enterprise features
      - NEO4J_ACCEPT_LICENSE_AGREEMENT=yes
      # Memory settings (Adjust based on your machine)
      - NEO4J_dbms_memory_heap_initial__size=1G
      - NEO4J_dbms_memory_heap_max__size=2G
      # Enable APOC custom procedures
      - NEO4J_dbms_security_procedures_unrestricted=apoc.*,gds.*
    volumes:
      - ./neo4j_data:/data
      - ./neo4j_plugins:/plugins
    healthcheck:
      test: ["CMD-SHELL", "wget --no-verbose --tries=1 --spider localhost:7474 || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5

  # -----------------------------
  # 2. Your Python LLM App
  # -----------------------------
  llm-app:
    build: .
    container_name: llm_knowledge_graph_app
    depends_on:
      neo4j-db:
        condition: service_healthy
    environment:
      - NEO4J_URI=neo4j://neo4j-db:7687
      - NEO4J_USERNAME=neo4j
      - NEO4J_PASSWORD=password123
      - OPENAI_API_KEY=${OPENAI_API_KEY} # Reads from your local shell or .env file
    volumes:
      - .:/app # Live reload: changes in your folder reflect inside container
    # Keep the container running indefinitely so you can enter the CLI
    command: tail -f /dev/null
