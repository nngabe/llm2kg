{
  "metadata": {
    "timestamp": "2026-01-06T21:50:48.301756",
    "duration_ms": 55646,
    "test_case_count": 8,
    "judge_model": "gpt-5.2",
    "enabled_layers": [
      "retrieval",
      "agentic",
      "integrity",
      "generation"
    ]
  },
  "summary": {
    "overall_score": 0.5761664653784219,
    "overall_passed": false
  },
  "layers": {
    "retrieval": {
      "layer": "retrieval",
      "overall_score": 0.5625,
      "passed": false,
      "metrics": [
        {
          "metric_name": "Contextual Precision",
          "layer": "retrieval",
          "score": 0.25,
          "passed": false,
          "threshold": 0.7,
          "details": {
            "test_case_count": 2,
            "valid_count": 2,
            "individual_scores": [
              0.0,
              0.5
            ]
          },
          "error": null,
          "latency_ms": 0
        },
        {
          "metric_name": "Contextual Recall",
          "layer": "retrieval",
          "score": 0.5,
          "passed": false,
          "threshold": 0.6,
          "details": {
            "test_case_count": 2,
            "valid_count": 2,
            "individual_scores": [
              0.0,
              1.0
            ]
          },
          "error": null,
          "latency_ms": 0
        },
        {
          "metric_name": "Graph Traversal Efficiency",
          "layer": "retrieval",
          "score": 1.0,
          "passed": true,
          "threshold": 0.4,
          "details": {
            "test_case_count": 2,
            "valid_count": 2,
            "individual_scores": [
              1.0,
              1.0
            ]
          },
          "error": null,
          "latency_ms": 0
        },
        {
          "metric_name": "Subgraph Connectivity",
          "layer": "retrieval",
          "score": 0.5,
          "passed": false,
          "threshold": 0.5,
          "details": {
            "test_case_count": 2,
            "valid_count": 2,
            "individual_scores": [
              1.0,
              0.0
            ]
          },
          "error": null,
          "latency_ms": 9
        }
      ]
    },
    "agentic": {
      "layer": "agentic",
      "overall_score": 0.6225,
      "passed": false,
      "metrics": [
        {
          "metric_name": "Tool Selection Accuracy",
          "layer": "agentic",
          "score": 0.49,
          "passed": false,
          "threshold": 0.8,
          "details": {
            "test_case_count": 2,
            "valid_count": 2,
            "individual_scores": [
              0.88,
              0.1
            ]
          },
          "error": null,
          "latency_ms": 12267
        },
        {
          "metric_name": "Argument Correctness",
          "layer": "agentic",
          "score": 0.0,
          "passed": false,
          "threshold": 0.85,
          "details": {
            "test_case_count": 2,
            "valid_count": 2,
            "individual_scores": [
              0.0,
              0.0
            ]
          },
          "error": null,
          "latency_ms": 11704
        },
        {
          "metric_name": "Loop Efficiency",
          "layer": "agentic",
          "score": 1.0,
          "passed": true,
          "threshold": 0.6,
          "details": {
            "test_case_count": 2,
            "valid_count": 2,
            "individual_scores": [
              1.0,
              1.0
            ]
          },
          "error": null,
          "latency_ms": 0
        },
        {
          "metric_name": "Rejection Sensitivity",
          "layer": "agentic",
          "score": 1.0,
          "passed": true,
          "threshold": 0.7,
          "details": {
            "test_case_count": 2,
            "valid_count": 2,
            "individual_scores": [
              1.0,
              1.0
            ]
          },
          "error": null,
          "latency_ms": 0
        }
      ]
    },
    "integrity": {
      "layer": "integrity",
      "overall_score": 1.0,
      "passed": true,
      "metrics": [
        {
          "metric_name": "Schema Adherence",
          "layer": "integrity",
          "score": 1.0,
          "passed": true,
          "threshold": 0.95,
          "details": {
            "test_case_count": 2,
            "valid_count": 2,
            "individual_scores": [
              1.0,
              1.0
            ]
          },
          "error": null,
          "latency_ms": 0
        },
        {
          "metric_name": "Entity Disambiguation",
          "layer": "integrity",
          "score": 1.0,
          "passed": true,
          "threshold": 0.9,
          "details": {
            "test_case_count": 2,
            "valid_count": 2,
            "individual_scores": [
              1.0,
              1.0
            ]
          },
          "error": null,
          "latency_ms": 0
        },
        {
          "metric_name": "Source Citation Accuracy",
          "layer": "integrity",
          "score": 1.0,
          "passed": true,
          "threshold": 0.8,
          "details": {
            "test_case_count": 2,
            "valid_count": 2,
            "individual_scores": [
              1.0,
              1.0
            ]
          },
          "error": null,
          "latency_ms": 0
        }
      ]
    },
    "generation": {
      "layer": "generation",
      "overall_score": 0.11966586151368759,
      "passed": false,
      "metrics": [
        {
          "metric_name": "Faithfulness",
          "layer": "generation",
          "score": 0.05344202898550725,
          "passed": false,
          "threshold": 0.75,
          "details": {
            "test_case_count": 2,
            "valid_count": 2,
            "individual_scores": [
              0.06521739130434782,
              0.041666666666666664
            ]
          },
          "error": null,
          "latency_ms": 0
        },
        {
          "metric_name": "Answer Relevance",
          "layer": "generation",
          "score": 0.25,
          "passed": false,
          "threshold": 0.7,
          "details": {
            "test_case_count": 2,
            "valid_count": 2,
            "individual_scores": [
              0.0,
              0.5
            ]
          },
          "error": null,
          "latency_ms": 0
        },
        {
          "metric_name": "Citation Recall",
          "layer": "generation",
          "score": 0.05555555555555555,
          "passed": false,
          "threshold": 0.6,
          "details": {
            "test_case_count": 2,
            "valid_count": 2,
            "individual_scores": [
              0.1111111111111111,
              0.0
            ]
          },
          "error": null,
          "latency_ms": 31291
        }
      ]
    }
  },
  "report_metadata": {
    "generated_at": "2026-01-06T21:51:43.578911",
    "report_type": "json",
    "version": "1.0"
  }
}